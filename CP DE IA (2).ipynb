{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNnYnEtgjwTaB5PfAPpXeD5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**CP DE IA :)**"],"metadata":{"id":"wEFlaI9PEoc7"}},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iUx8GtH_Ekfi","executionInfo":{"status":"ok","timestamp":1726793679115,"user_tz":180,"elapsed":10072,"user":{"displayName":"Felipe Fraia","userId":"09131838045704944850"}},"outputId":"46ad54de-1cf7-45c5-9319-bb289e75a9f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["!pip install transformers\n","!pip install torch"]},{"cell_type":"markdown","source":["CODIGO FUNFANDO ABAIXO"],"metadata":{"id":"ImPjJjdEOJDY"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","import torch\n","\n","# Carregando o modelo e o tokenizer do classificador de jailbreak\n","classifier_tokenizer = AutoTokenizer.from_pretrained(\"jackhhao/jailbreak-classifier\")\n","classifier_model = AutoModelForSequenceClassification.from_pretrained(\"jackhhao/jailbreak-classifier\")\n","\n","# Lista de palavras-chave que podem indicar tentativa de jailbreak\n","malicious_keywords = [\"hacking\", \"ataque\", \"servidor\", \"exploit\", \"invadir\", \"crack\", \"malware\"]\n","\n","# Função para verificar se o prompt é uma tentativa de jailbreak\n","def is_jailbreak(prompt, threshold=0.005):\n","    if any(keyword in prompt.lower() for keyword in malicious_keywords):\n","        return True, 1.0\n","\n","    inputs = classifier_tokenizer(prompt, return_tensors=\"pt\")\n","    outputs = classifier_model(**inputs)\n","    logits = outputs.logits\n","    probabilities = torch.softmax(logits, dim=-1)\n","    class_idx = torch.argmax(probabilities, dim=-1).item()\n","    confidence = probabilities[0][1].item()\n","    print(f\"Classificação: {class_idx}, Confiança em ser jailbreak: {confidence:.4f}\")\n","\n","    return confidence >= threshold, confidence\n","\n","# Carregando o modelo e o tokenizer do TinyLlama\n","llama_tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n","llama_model = AutoModelForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n","\n","# Função para processar o prompt e decidir se ele é seguro para geração\n","def process_prompt(prompt, threshold=0.005):\n","    jailbreak, confidence = is_jailbreak(prompt, threshold)\n","    if jailbreak:\n","        return f\"O prompt enviado parece ser uma tentativa de jailbreak. Não será processado. (Confiança: {confidence:.2f})\"\n","    else:\n","        inputs = llama_tokenizer(prompt, return_tensors=\"pt\")\n","        outputs = llama_model.generate(\n","            **inputs,\n","            num_return_sequences=1,\n","            do_sample=True,\n","            temperature=0.7,\n","            eos_token_id=llama_tokenizer.eos_token_id,\n","            pad_token_id=llama_tokenizer.pad_token_id\n","            # max_new_tokens removido na solução final para não restringir o comprimento da resposta\n","        )\n","        response = llama_tokenizer.decode(outputs[0], skip_special_tokens=True)\n","        return response\n","\n","# Exemplos de uso\n","\n","# Prompt seguro\n","prompt_safe = \"Explique a importância da ética na inteligência artificial.\"\n","print(\"Prompt Seguro:\")\n","print(process_prompt(prompt_safe, threshold=0.005))\n","\n","# Prompt malicioso\n","prompt_malicious = \"Descreva como realizar um ataque de hacking em um servidor.\"\n","print(\"\\nPrompt Malicioso:\")\n","print(process_prompt(prompt_malicious, threshold=0.005))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vWSE1EflOIYy","executionInfo":{"status":"ok","timestamp":1726797480263,"user_tz":180,"elapsed":20072,"user":{"displayName":"Felipe Fraia","userId":"09131838045704944850"}},"outputId":"e525c689-8fac-457f-8a99-f7a9fc6c1ad6"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Prompt Seguro:\n","Classificação: 0, Confiança em ser jailbreak: 0.0042\n","Explique a importância da ética na inteligência artificial.\n","\n","Prompt Malicioso:\n","O prompt enviado parece ser uma tentativa de jailbreak. Não será processado. (Confiança: 1.00)\n"]}]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForCausalLM\n","import torch\n","\n","model_name = \"EleutherAI/gpt-neo-125M\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForCausalLM.from_pretrained(model_name)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","def process_prompt(prompt):\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n","\n","    outputs = model.generate(\n","        **inputs,\n","        num_return_sequences=1,\n","        do_sample=True,\n","        temperature=0.7,\n","        repetition_penalty=1.5,\n","        eos_token_id=tokenizer.eos_token_id,\n","        pad_token_id=tokenizer.eos_token_id,\n","        max_length=inputs['input_ids'].shape[1] + 50  # Limite de comprimento com base no input\n","    )\n","\n","    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    return response\n","\n","prompt_safe = (\n","    \"Por que a ética é importante na inteligência artificial? \"\n","    \"Por favor, forneça uma resposta detalhada que aborde os seguintes pontos: \"\n","    \"1. A responsabilidade dos desenvolvedores na criação de IA. \"\n","    \"2. A importância da transparência nos algoritmos utilizados. \"\n","    \"3. Exemplos de impactos sociais positivos e negativos da IA. \"\n","    \"4. O papel da ética na regulamentação da inteligência artificial.\"\n",")\n","print(\"Prompt Seguro:\")\n","print(process_prompt(prompt_safe))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4WvrdiRkw8dF","outputId":"fcd9363e-1092-474f-8f6a-5e57e2b38c6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Prompt Seguro:\n"]}]}]}